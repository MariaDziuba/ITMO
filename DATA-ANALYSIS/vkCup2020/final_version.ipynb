{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7Vp3HhjZOP8"
   },
   "source": [
    "## Imports and boring stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebOi-_BdZ-Cu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sd3Nv3ma7IA"
   },
   "source": [
    "## Competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qfa6AUWSa-MZ"
   },
   "outputs": [],
   "source": [
    "def get_smoothed_log_mape_column_value(responses_column, answers_column, epsilon):\n",
    "    return np.abs(np.log(\n",
    "        (responses_column + epsilon)\n",
    "        / (answers_column + epsilon)\n",
    "    )).mean()\n",
    "\n",
    "\n",
    "def get_smoothed_mean_log_accuracy_ratio(answers, responses, epsilon=0.005):\n",
    "    log_accuracy_ratio_mean = np.array(\n",
    "      [\n",
    "          get_smoothed_log_mape_column_value(responses.at_least_one, answers.at_least_one, epsilon),\n",
    "          get_smoothed_log_mape_column_value(responses.at_least_two, answers.at_least_two, epsilon),\n",
    "          get_smoothed_log_mape_column_value(responses.at_least_three, answers.at_least_three, epsilon),\n",
    "      ]\n",
    "  ).mean()\n",
    "\n",
    "    percentage_error = 100 * (np.exp(log_accuracy_ratio_mean) - 1)\n",
    "\n",
    "    return percentage_error.round(\n",
    "      decimals=2\n",
    "  )\n",
    "\n",
    "def cost(answers, responses, epsilon=0.005):\n",
    "    log_accuracy_ratio_mean = np.array(\n",
    "      [\n",
    "          get_smoothed_log_mape_column_value(responses[0], answers[0], epsilon),\n",
    "          get_smoothed_log_mape_column_value(responses[1], answers[1], epsilon),\n",
    "          get_smoothed_log_mape_column_value(responses[2], answers[2], epsilon),\n",
    "      ]\n",
    "  ).mean()\n",
    "\n",
    "    percentage_error = 100 * (np.exp(log_accuracy_ratio_mean) - 1)\n",
    "\n",
    "    return percentage_error.round(\n",
    "      decimals=2\n",
    "  )\n",
    "\n",
    "def cv_cost(est, X, y):\n",
    "    return cost(est.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yS2o2nlhbFR5"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0kT5VyOZ6xr"
   },
   "outputs": [],
   "source": [
    "def load_csv(fp):\n",
    "    return pd.read_csv(fp, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuyZ9_aHZ0Nv"
   },
   "outputs": [],
   "source": [
    "his_df = load_csv('itmo-andan-competition/history.csv')\n",
    "us_df = load_csv('itmo-andan-competition/users.csv').astype('category')\n",
    "xval_df = load_csv('itmo-andan-competition/ads.csv')\n",
    "yval_df = load_csv('itmo-andan-competition/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOe271zfVmP4"
   },
   "source": [
    "## How we cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VswQ5PJI97Lk"
   },
   "outputs": [],
   "source": [
    "def crossval(model, xval_df, yval_df, train_sizes=[0.7, 0.75, 0.8]):\n",
    "    scores = []\n",
    "    for ts in train_sizes:              \n",
    "        mid_scores = []\n",
    "        data_sorted = pd.concat([xval_df, yval_df], axis=1).sort_values(by='hour_start')\n",
    "        x_cols, y_cols = xval_df.columns, yval_df.columns\n",
    "        n_train_samples = int(len(data_sorted) * ts)\n",
    "\n",
    "        train_df = data_sorted[x_cols].iloc[:n_train_samples]\n",
    "        y_train = te(data_sorted[y_cols].iloc[:n_train_samples].values)\n",
    "\n",
    "        test_df = data_sorted[x_cols].iloc[n_train_samples:]\n",
    "        y_test = te(data_sorted[y_cols].iloc[n_train_samples:].values)\n",
    "\n",
    "        av_his = his_df[his_df['hour'] < test_df['hour_start'].min()]\n",
    "\n",
    "        X_train, cat_features = fe(train_df, av_his)\n",
    "        X_test, _ = fe(test_df, av_his)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        clear_output()\n",
    "        mid_scores.append(cost(pe(y_test), pe(model.predict(X_test))))\n",
    "        scores.append(mid_scores)\n",
    "    print('\\n'.join([('%f percenst split: '+str(scores[i])) % train_sizes[i] for i in range(len(scores))]))\n",
    "    scores = np.array(scores)\n",
    "    return (scores.mean(axis=0), scores.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcSLsIOXKu_O"
   },
   "source": [
    "# Machine learning actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4qqsfwSlr_8"
   },
   "outputs": [],
   "source": [
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return x.quantile(n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_\n",
    "\n",
    "def get_ta(ad):  # return df of users\n",
    "    ids = [int(i) for i in ad['user_ids'].split(',')]\n",
    "    aus = ad['audience_size']\n",
    "    ta = us_df[us_df['user_id'].isin(ids)]  # target auditory\n",
    "    assert ta.shape[0] == aus\n",
    "    return ta\n",
    "\n",
    "def get_n_tcities(ta):  # return number of target cities\n",
    "    return sum([1 for i in ta['city_id'].value_counts().values if i != 0])\n",
    "\n",
    "def get_ages_mean_std(ta):  # return mean and std of ages distr without outliers\n",
    "    ta = ta.astype('int')\n",
    "    ages = ta[(ta['age'] >= 14) & (ta['age'] <= 80)]['age']\n",
    "    if ages.empty:\n",
    "        ages = np.array([0])\n",
    "    return [ages.mean(), ages.std()]\n",
    "\n",
    "def get_male_perc(ta):  # percentage of men\n",
    "    return ta['sex'].value_counts(normalize=True)[1] * 100\n",
    "\n",
    "def get_new_features(ad):\n",
    "    ta = get_ta(ad)\n",
    "    ta = ta.astype('int')\n",
    "    new_cols = []\n",
    "    new_cols.append(get_n_tcities(ta))\n",
    "    new_cols += get_ages_mean_std(ta)\n",
    "    new_cols.append(get_male_perc(ta))\n",
    "    return new_cols\n",
    "\n",
    "def users_hist_features(ad, hd_grouped):\n",
    "    # returns:\n",
    "    # 1. mean number of seen ads for target auditory\n",
    "    return pd.Series(hd_grouped.loc[ad.users].agg(['mean']).values.flatten(), index=['mean_ads_seen_per_user',])\n",
    "\n",
    "def pub_us_hist_features(ad, hist_grouped):\n",
    "    ta = [int(i) for i in ad['user_ids'].split(',')]\n",
    "    pubs = [int(i) for i in ad.publishers.split(',')]\n",
    "    ta_tp_history = hist_grouped[((hist_grouped['publisher'].isin(pubs)) & (hist_grouped['user_id'].isin(ta)))]\n",
    "    h = ta_tp_history.groupby('user_id').agg(['sum'])\n",
    "    h.columns = ['publisher_size', 'n_seen_ads_on_theese_platforms']\n",
    "    agg_funcs = ['median', 'mean', 'std', 'sum', percentile(0.25), percentile(0.75)]\n",
    "    x = h['n_seen_ads_on_theese_platforms'].agg(agg_funcs)\n",
    "    ### можно выбросить тех, кто ни разу не видел \n",
    "    x.index = [\n",
    "               'ta_tp_seen_ads_median', 'ta_tp_seen_ads_mean', 'ta_tp_seen_ads_std', 'ta_tp_seen_ads_sum', 'ta_tp_seen_ads_q1', 'ta_tp_seen_ads_q3'\n",
    "               ]\n",
    "    x['n_of_people_who_didnt_see'] = len(ta) - len(h)\n",
    "    x['n_of_people_who_saw_at_least_once'] = h['n_seen_ads_on_theese_platforms'].value_counts()[0:].sum()\n",
    "    x['n_of_people_who_saw_at_least_twice'] = h['n_seen_ads_on_theese_platforms'].value_counts()[1:].sum()\n",
    "    x['n_of_people_who_saw_at_least_three_times'] = h['n_seen_ads_on_theese_platforms'].value_counts()[2:].sum()\n",
    "    return x\n",
    "\n",
    "def fe(X, hist):  # feature engeneering, returns enged X, cat_features\n",
    "    X['users'] = [list(map(int, i.split(','))) for i in X['user_ids']] \n",
    "    X['time_shown'] = X['hour_end'] - X['hour_start']\n",
    "    hist['day_hour'] = hist['hour'] % 24\n",
    "    new_X = pd.DataFrame()\n",
    "\n",
    "    # basic ad features\n",
    "    new_X['cpm'] = X['cpm']\n",
    "    new_X['time_shown'] = X['time_shown']\n",
    "    new_X['audience_size'] = X['audience_size']\n",
    "\n",
    "    # user info features\n",
    "    ui_X = X.apply(get_new_features, axis=1, result_type='expand')\n",
    "    ui_cols = ['n_target_cities', 'tage_mean', 'tage_std', 'male_perc']\n",
    "    ui_X.columns = ui_cols\n",
    "    new_X = pd.concat([new_X, ui_X], axis=1)\n",
    "\n",
    "    # history features 1\n",
    "    hist_grouped = hist.groupby('user_id')[['cpm']].agg(['size'])\n",
    "    us_hist_X = X.apply(\n",
    "        users_hist_features, axis=1, result_type='expand', args=(hist_grouped,),\n",
    "    )\n",
    "    new_X = pd.concat([new_X, us_hist_X], axis=1)\n",
    "\n",
    "    # history features 2\n",
    "    hist_grouped = hist.groupby(['publisher', 'user_id'])['cpm'].agg(['size']).reset_index()\n",
    "    pub_us_hist_X = X.apply(\n",
    "        pub_us_hist_features, axis=1, result_type='expand', args=(hist_grouped,)\n",
    "    )\n",
    "    new_X = pd.concat([new_X, pub_us_hist_X], axis=1)\n",
    "\n",
    "    # define categorical features\n",
    "    cat_features = []\n",
    "    new_X[cat_features] = new_X[cat_features].astype('int')\n",
    "    poly = PolynomialFeatures(2)\n",
    "    new_X = poly.fit_transform(new_X)\n",
    "    return (new_X, cat_features)\n",
    "\n",
    "def pe(y):  # postprocess target\n",
    "    return y ** 2\n",
    "\n",
    "def te(y):  # target engeneering\n",
    "    return np.sqrt(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHtLVnjFkrrb"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([   46,   143,   351,   359,   513,\\n            ...\\n            25575, 25961, 26950, 27738, 27754],\\n           dtype='int64', name='user_id', length=113). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-547a65dbdb9b>\u001b[0m in \u001b[0;36mfe\u001b[0;34m(X, hist)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# history features 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mhist_grouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cpm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     us_hist_X = X.apply(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0musers_hist_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'expand'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_grouped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m         )\n\u001b[0;32m-> 7768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-547a65dbdb9b>\u001b[0m in \u001b[0;36musers_hist_features\u001b[0;34m(ad, hd_grouped)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# returns:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# 1. mean number of seen ads for target auditory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhd_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_ads_seen_per_user'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpub_us_hist_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([   46,   143,   351,   359,   513,\\n            ...\\n            25575, 25961, 26950, 27738, 27754],\\n           dtype='int64', name='user_id', length=113). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, cat_features = fe(xval_df, his_df)\n",
    "y = te(yval_df.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbbWjBFRnEwe"
   },
   "source": [
    "## Define base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAnUccTalS8v"
   },
   "outputs": [],
   "source": [
    "class MyCatboostRegressor(CatBoostRegressor):\n",
    "    def predict(self, data):\n",
    "        preds = super(MyCatboostRegressor, self).predict(data)\n",
    "        preds = np.maximum(preds, 0.)\n",
    "        preds = np.minimum(preds, 1.)\n",
    "        preds = np.round(preds, 4)\n",
    "        return preds\n",
    "\n",
    "\n",
    "class WorldGreatestModel(object):\n",
    "    # basically, simple ensemble\n",
    "    def __init__(self, estimators=None):\n",
    "        self.estimators = estimators\n",
    "    \n",
    "    def fit(self, X, y, n_folds=4):\n",
    "        for i in range(len(self.estimators)):\n",
    "            self.estimators[i].fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = [self.postprocess_y(self.estimators[i].predict(X)) for i in range(len(self.estimators))]\n",
    "        preds = sum(preds) / len(self.estimators)\n",
    "        return preds\n",
    "\n",
    "    def postprocess_y(self, preds):\n",
    "        preds = np.maximum(preds, 0.)\n",
    "        preds = np.minimum(preds, 1.)\n",
    "        preds = np.round(preds, 4)\n",
    "        return preds\n",
    "\n",
    "    def save_models(self, fps):\n",
    "        assert len(fps) == len(self.estimators)\n",
    "        for i in range(len(fps)):\n",
    "            self.estimators[i].save_model(fps[i], 'json')\n",
    "\n",
    "    def load_models(self, fps):\n",
    "        self.estimators = [MyCatboostRegressor().load_model(fp, 'json') for fp in fps]\n",
    "        return self\n",
    "\n",
    "n_iterations = 3000\n",
    "\n",
    "estimators = [\n",
    "    MyCatboostRegressor(\n",
    "      loss_function= 'MultiRMSE',\n",
    "      iterations= n_iterations,\n",
    "      random_seed=2,\n",
    "    ),\n",
    "    MyCatboostRegressor(\n",
    "      loss_function= 'MultiRMSE',\n",
    "      iterations=n_iterations,\n",
    "      random_seed=189,\n",
    "    ),\n",
    "    MyCatboostRegressor(\n",
    "      loss_function= 'MultiRMSE',\n",
    "      iterations=n_iterations,\n",
    "      random_seed=101,\n",
    "    ),\n",
    "    MyCatboostRegressor(\n",
    "      loss_function= 'MultiRMSE',\n",
    "      iterations=n_iterations,\n",
    "      random_seed=42,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model = WorldGreatestModel(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uDwSDbeGwek"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    ensemble_size = 4\n",
    "    file_names = ['tuned_ensemble/' + 'model' + str(i) for i in range(ensemble_size)]\n",
    "    model.fit(X, y)\n",
    "    model.save_models(file_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYo2pInGlV2B"
   },
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSOffQ4plde8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if True:\n",
    "    kfold5 = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    kfold9 = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "    scores_mean, scores_std = crossval(\n",
    "        model, xval_df, yval_df, train_sizes=kfold9 \n",
    "    )\n",
    "    print('Mean scores', scores_mean)\n",
    "    print('Std of scores', scores_std)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "D7Vp3HhjZOP8",
    "3sd3Nv3ma7IA",
    "yS2o2nlhbFR5",
    "3BTWdwIzfqoX",
    "rZLS3_GrIzWe",
    "rnUaB1RbWv6p",
    "NMEiMv6_XvV5",
    "3zrfG2NdeHvR",
    "RyQeHVH4xjr2",
    "dupEJZ2rxrna",
    "W-0Fe2EcwSFV"
   ],
   "name": "final_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
